---
title: "最強AI【LuckyJ】とNAGA/Suphx徹底比較！技術の違いから見える打牌の違い"
publishedAt: 2023-09-06
tags: ["AI", "Lucky J", "NAGA", "Suphx", "お知らせ", "ゆうせー", "天鳳", "戦略", "戦術", "雀魂", "麻雀"]
category: "お知らせ"
legacySlug: "2023/09/06/luckyj_vs_naga_and_suphx"
draft: false
image: "https://r2.modern-jan.com/thumbnails/luckyj_vs_naga_and_suphx.avif"
---

import LinkCard from '../../components/LinkCard.astro';

2023年5月30日、ネット麻雀界隈に激震が走りました。

LuckyJという麻雀AIが一ヶ月ほどで特上卓で10段を達成しました。

しかも特上卓東南戦で1000戦以上打って安定段位が**約10.7段**という圧倒的な成績で。

![](https://r2.modern-jan.com/2023/08/image-5-1024x953.avif)

（画像出典：[テンセント](https://mp.weixin.qq.com/s/yGH8rH05XvSFqWMl4VZWFw)）

![](https://r2.modern-jan.com/2023/09/image-6-1024x269.avif)

（[天鳳ランキングサイト](http://otokomyouri.com/Ranking/Ranking.aspx)のスクリーンショット）

皆さんがご存知の麻雀AIである**Suphxで25位**、**NAGAは291位**ということを思えばどれほど驚異的な数字かおわかりかと思います。

もちろん安定段位という値はたかだか1000回の桁で見たときに上ブレ・下ブレを含むものであり、必ずしも正確な実力を示せているとは言えませんが麻雀打ちの感覚としてこれは十分に強いと感じる数字ではあると思います。

更に驚かせたのがその打牌です。以下のような記事が出るほどです。

![](https://r2.modern-jan.com/2023/08/image-7.avif)

AIといえば効率重視で向聴数を落とすような柔らかい打牌はほとんどしないようなイメージでした。しかしLuckyJは超メリハリ打法でこう言ってはなんですが「人間臭い」ほど。

この記事はそのような麻雀を身に着けた**LuckyJに用いられている技術についてSuphxやNAGAと比較しながら「麻雀打ちに向けて」解説するものです。**

技術そのものについて細かく説明するのではなく、**LuckyJの打牌意図を察するための一助となるべく**、LuckyJの**独自性の解説**と私なりの**推測**を提供したいという趣旨になっています。

_著者は情報工学の修士号を取得しているので、最低限のAIの知識は持ち合わせていますが、最新のAIのアルゴリズムや論文を把握しているわけではありません。よって間違いを含む場合があります。お気づきになった場合はTwitterまでご連絡ください。([@kbkn3](https://twitter.com/kbkn3))_  
_また専門知識を省くことでわかりやすさを重視しています。強化学習や教師あり学習の違いを取り上げなかったり、学習を効率的に進めるためのテクニックなどは意図的に省いていることがあります。_

## 近年のAI事情

機械学習（データからコンピュータが自ら学習すること）の歴史はコンピュータ黎明期から始まる長いものですが、最近はディープラーニング（深層学習）という手法で様々なタスクをクリアして話題になっています。  
ディープラーニングの元となるアイディア自体は古いものだと1943年頃から存在し、今の深層学習の原型は1979年には登場していますが、いくつかのハードルが存在したため、昨今のような驚異的な成果を出すまでには至りませんでした。

そのハードルは大きく分けると

・**技術的なハードル**：基礎理論はあっても、アルゴリズムが未熟で実用の段階になかった。

・**計算量のハードル**：データからのAIが学習する際の計算量が膨大で、現実的でなかった。

・**学習用データの量のハードル**：AIにデータを与えて学習させるため、一般的にデータは多ければ多いほど良い。

の3種類です。このハードルがあるためにディープラーニングは理論があっても流行らず、他の手法によって開発されたAIがチェッカーやチェスといった盤面のパターンが少ないものから人間に勝利してきました。

しかし2006年に発表された論文に掲載された技術がディープラーニングの技術的なハードルをクリアしました。  
またコンピュータのスペックの急激な向上によって求められる計算量のハードルをクリアし、インターネットの発展によって学習に使用できるデータが流通することで、2000年代末から2010年代にかけて急激に深層学習が成果を出し、普及しました。

最も有名になったのは2015年に人間のプロ囲碁棋士を互先（ハンディキャップなし）で破った初のAIとなった**AlphaGo**でしょう。

その後、2017年に1対1のテキサスホールデム（ポーカー）で**Libratus**が人間に圧勝し、2019年には6人対戦のテキサスホールデムでも**Pluribus**が人間に圧勝しました。

![](https://r2.modern-jan.com/2023/08/suphx-5-1024x576.avif)

（画像出典：Microsoft）

この記事を読むにあたって抑えてほしいポイントは、

*   完全情報ゲームにおいては理論・マシンスペックの進化に伴って、観測可能な盤面の情報量が多いゲームに対応できるようになった
*   不完全情報ゲームは隠された不完全情報（相手の手）を考慮したプレイが必要になるため、完全情報ゲームよりアプローチが難しい
    *   隠された情報が多いほど難しい。隠された情報のパターンが比較的少ないポーカーでまず成功した

ということです。

NAGAの公式解説記事においては

> 麻雀は相手の手牌が見えず（不完全情報）、次にどの牌を引くのかわからない（不確定）という難しさのあるゲームです。 プレイヤーが4人のため次の自分の手番の状態が予測がしづらい点や、1試合が複数局からなる半荘という単位で最終的な成績が決定されるため長期的な戦略が必要なことも麻雀の難しい点です。 
> 
> 深層学習麻雀AI「NAGA」 - DWANGO MEDIA VILLAGE

と書かれています。麻雀に対するアプローチの難しさが伝わると思います。

## AIの打牌判断の根拠

### 旧来の麻雀AI

旧来の麻雀AIは人間のセオリーをプログラムコードとしてルール化することで実現していました。

しかし人間の強者が「バランスが…絶妙にこっちな気がする」などと言っている通り、麻雀は局面も無限に存在し不確定な情報も多いため、セオリーだけでは強者たり得ません。

そこで最近流行りのディープラーニング（深層学習）を用いて、大量の学習から最適な打牌を選択できるように学ばせているのが最新の麻雀AIです。

### 最新の麻雀AI

AIに触れたことがない人にとってのAIの打牌根拠を出力させたイメージは「打1pは和了率2% up、放銃率3%、打1sで…」のようなロジカルで理路整然としたものだと思われがちですが、実際にはそうではありません。

誤解を恐れずに言うならば、**「多分これが得だと思ったから」**となります。学習の過程で「現在得られる局面の情報から打つべき牌はこれっぽい」を会得します。

正確にはNAGAの牌譜検討画面を見ればわかるように「打3mが良いっぽい。次に良さそうなのが3sかな〜」という、経験（学習）から来る感覚的なものと言ってもいいでしょう。

![](https://r2.modern-jan.com/2023/08/image-9-1024x980.avif)

NAGA牌譜画面（https://twitter.com/NAGA025/status/1476807899452440583?s=20）

実際のAIからの出力としては「この盤面で打つべき牌は打3mが40%、打3sが20%、その他の選択肢は5%」というような確率として出力され、この中で値が最も大きいものが選択されるというものです。

正確に言うならば

*   「この盤面で打つべき牌は打3mが40%、打3sが20%、その他の選択肢は5%」と共に「打1pは和了率2% up、放銃率3%、打1sは…となりそう」というおまけ情報も出力させることもできる
*   「打1pは和了率2% up、放銃率3%、打1sは…**だから、**この盤面で打つべき牌は打3m」とロジカルに導き出しているわけではない

ということです。

## NAGAのアプローチ

NAGAのアプローチは天鳳位を始めとした天鳳鳳凰卓に在籍する**強者を模倣する**、というものです。

どのプレイヤーを題材にしているかは明かしていませんが、天鳳鳳凰卓の強者の牌譜を材料として学習しています。つまり「〇〇さんなら✕を切りそう」を学習しているわけです。

AIの構成は

*   打牌モデル
*   副露モデル
*   立直モデル
*   槓モデル

の4つのモデルで構成されており、これらが自身の手牌、4人の河、副露、点数、見えていない牌の数など、現在の局面を完全に再現できる情報を入力として打牌や副露するか、立直するかなどを判断しています。

また旧来の麻雀AIではオリの判断をさせることに課題がありました。しかし牌譜からの学習において攻めとオリの判断を学んでいます。

NAGAの学習の際には局数の情報も与えられているため、ゲームの進行具合に合わせた長期戦略も学習しています。

![](https://r2.modern-jan.com/2023/09/reach_naga-1024x503.avif)

![](https://r2.modern-jan.com/2023/09/reach_human-1024x503.avif)

_NAGAと人間(鳳凰卓)の局ごとの立直率の推移の比較（深層学習麻雀AI「NAGA」 - DWANGO MEDIA VILLAGE　より）_

### 注：現行NAGA

現在のNAGA解析サービスでは5種類のモデル（打ち筋タイプ）が存在します。

これらはNAGA v2.1となっており、8段到達時のNAGAやv0.5-α （9段到達）、NAGA解析サービス提供時のv1.2-ωよりも強いモデルです。

**現行NAGAはNAGA10段到達モデルより十分に強いことがNAGA公式Twitterによって[示されています](https://twitter.com/NAGA025/status/1509779535541067778?s=20)**。

![](https://r2.modern-jan.com/2023/08/image-11-1024x762.avif)

NAGA 新タイプの要素（https://twitter.com/NAGA025/status/1493862312469745664?s=20）

これらのモデルは特定少数の複数の強者の選択を総合的に考えて打牌を選択することで結果的にバランスが良くなり、強くなったそうです。

画像はニシキの説明ですが、恐らく各タイプについても同様に放銃率、副露率や和了役の割合などで複数プレイヤーを選んで学習材料にしているのでしょう。そしてバージョンアップごとにアルゴリズムのチューニングを行い、日々強くなっています。

この要素を含めると現行NAGAは「**強者を模倣してバランスを高めたAI**」と言えるでしょう。

### NAGAの弱点

*   **オリや仕掛け・リーチへの対応の判断以外でのシャンテン数下げる判断が苦手**
*   **槓モデルの振る舞いが限定的**

などが挙げられています。

これらの理由については**私個人の予想**となりますが、

*   シャンテン数が進むこと・和了率予想・打点予想に対して報酬が用意され、学習に活かしているために**シャンテン数を下げることが苦手**
*   槓の選択は牌譜中でも**レアな行動であるため学習に十分な局面数がない**ことで、槓によって生じる出来事（自身の打点上昇、他家の打点上昇、槓によって4枚目の牌がなくなること等）を適切に評価できていないことで適切な選択ができない

と考えています。

_（DWNAGO公式様、間違いなどあればご指摘お待ちしています。）_

## Suphxのアプローチ

Suphxは論文が出た時点のNAGA（8段到達当時）より優秀な成績を残しています。安定段位にして**8.74**段。当時としては最強です。

そんなSuphxがNAGAと一番違うポイントは「**AIに大量に麻雀を打たせ、経験から優れたプレイを学習させた**」というところです。

では細かく見ていきましょう。

### AIの構成

まず、AIの構成を確認します。ここはNAGAとほとんど変わりません。

*   打牌モデル
*   チー判断モデル
*   ポン判断モデル
*   立直モデル
*   槓モデル

の5つのモデルで構成されています。大きな違いはアルゴリズムです。

### アルゴリズム（AIの仕組み）

NAGAとの大きな違いは学習の仕組みです。学習は2段階に分かれています。

1.  天鳳の上位ユーザーの牌譜を用いて5つのモデル（打牌・ポン・カン・チー・リーチモデル）を学習させる。
2.  1.で学習したAI同士で大量に対戦させ、その結果から更に学習させる。（自己対戦）

という流れです。

#### 1.牌譜からの学習

牌譜による学習はNAGAと近しいものと言えます。天鳳の鳳凰卓の牌譜を用いて麻雀強者の選択を模倣できるように学習させています。この段階で大雑把に牌効率、オリの方法を学んでいると言えます。

#### 2.AI同士の対戦から学習

この学習段階は、大雑把に言うと牌譜から学習済みのAI同士で大量に対戦し、良い結果が出たらプラスポイントを与え、悪い結果が出たらマイナスポイントを与えることでAIが経験を元に学習するというものです。

この段階ではいくつかの学習テクニックを用いて、効果的に学習をしています。

##### 2.1 半荘単位の報酬予測（Global Reward Prediction）

麻雀は1半荘で8局以上の局をプレイします。プレイヤーは局が終了するごとに点数移動を行い、オーラス終了時の点数によって最終順位が決定し、天鳳においては+90、+45、±0、-135という段位ポイントの報酬を獲得します。

つまり各局の点数移動だけ、ゲーム中の現順位だけをAIに対する報酬として与えても適切な報酬になりません。

・**点数移動が報酬として適切でない**：4人に1人しか和了できない麻雀において、各局の点数移動の結果だけを元にいい選択ができたかどうかは区別できない。良い選択ができたが結果として和了できない、もしくは捲り合いで放銃になる事もありえる。

・**現在順位が報酬として適切でない**：東1局の1000点の価値と南3局の着順の変わる1000点の価値には大きな違いがあるように、ゲーム進行度とその時の順位・得点差によって適切な打ち筋は異なる。つまり現在順位だけを報酬とするのは適切ではない。

よって現在の局の情報とそれまでの局の情報から最終的な持ち点を予測するAIを別個に学習させ、各局のプレイを評価させてSuphxに報酬を与える仕組みを設けています。

##### 2.2 不完全情報への対策（Oracle Guiding）

先に述べたように、AIに不完全情報ゲームを自ら学習させるのは難しい課題です。

Suphxでは効率的に学習させる目的で「最初は観戦者視点で学習し、徐々に見える情報を減らしながら学習する」というテクニックを用いていることが明かされています。つまり最初は全員が手牌を公開しながらの麻雀、徐々に鷲巣麻雀に変化し、最後は普通の麻雀に切り替えて学習をしています。論文によるとこのテクニックがかなり学習に効果的だったようです。

一方でこれは結果的に**他家の河がどのような手牌から生まれるかも効果的に学習している**かもしれません。捨て牌を読んだり、副露に危険な牌を読んだりといった部分に大きな影響を与えていると考えられます。

##### 3.3 相対的な手牌価値の予測（Prametric Monte-Carlo Policy Adaptation）

各局ごとに与えられる手牌の相対的な良し悪しによってプレイを変えるためのテクニックです。

メンタンピンが見える好配牌なら牌効率MAXで選択し、悪配牌ならば安全牌を持ちながらチャンタやホンイツ、七対子を見ながら守備的に進行したり、という戦略の切り替えはある程度麻雀の戦略を覚えてくると身につけるものですが、これは元々AIには不得意なものです。

そこで採用した手法が、

1.  配牌を除いた残りの牌から他家3人の手牌をランダムに何パターンも仮置いて、その中でどのような対局になるかの予想を生成する。
2.  その対局パターンを元に戦略を調整する

というものです。例えば、多井隆晴プロがYoutubeの麻雀勉強配信で話している、「7枚あるドラが自分の配牌に入ってなかったら他の誰かに1,2枚は入っている。それを前提にして手を組むべきだ」というような考え方に近いでしょうか。

[【中級戦術】咲乃もこが多井隆晴に学ぶ・29【魂天への道】| キンマWeb](https://kinmaweb.jp/archives/159736)

### Suphxまとめ

2ステップの学習から、強者の模倣から攻撃と守備という戦術を学び、AI同士の対戦の中から手牌価値やゲーム進行に合わせた戦略の切り替え、いわば大局観とメリハリ打法を学んでいるのがわかったと思います。

まとめるとSuphxはNAGAに比べて、「**大量の経験によって大局観とメリハリ打法を身に着けた**」AIと言えます。

Suphxの麻雀については書籍が出ていますので、まとめの章をぜひ御覧ください。

## LuckyJのアプローチ

ようやくLuckyJについて見ていきます。

以下の画像を見るとLuckyJの圧倒的な成績がわかると思います。

![](https://r2.modern-jan.com/2023/08/無題のプレゼンテーション-3.avif)

![](https://r2.modern-jan.com/2023/08/無題のプレゼンテーション-4.avif)

LuckyJを一言で表すならば「**ゲーム理論を麻雀に取り入れた現状最も麻雀の神に近付こうとしているAI**」です。

### AIの構成

NAGAやSuphxと異なり、構造は公開されていません。私個人としては概ねSuphxと同様の構成だと予想しています。

### アルゴリズム（AIの仕組み）

Suphxと似ている部分もあるのですが、大きく異なる点が2つあります。

1.  人間の牌譜を使っていない（自己対戦学習）
2.  ゲーム理論を取り入れて戦略を最適化している

の2点です。

#### 1\. 人間の牌譜を使っていない（自己対戦学習）

NAGA/Suphxは共に天鳳鳳凰卓の牌譜を用いて学習していますが、Lucky Jは一切人間を参考にせず、Lucky J同士の対戦の中で戦術のすべてを学習しています。

つまりSuphxのように人間の打ち筋をある程度習得してから大量の対戦の中で修正したというわけではなく、ひたすらに試行錯誤をして既存のセオリーと関係なく麻雀の戦術を学んでいます。

#### 2\. ゲーム理論を取り入れて戦略を最適化している

##### ゲーム理論とそのAI活用の難易度

ゲーム理論とは社会や自然における複数の主体（人や団体）が関わる意思決定の問題や行動の相互依存的状況を数学的なモデルを用いて研究する学問です。特にここで取り上げるのは**ナッシュ均衡**という考え方です。

**お互いのプレイヤーが戦略を変えることで利益をこれ以上増やすことができない戦略**が存在し、その戦略同士の均衡点が**ナッシュ均衡**です。ざっくりと説明すると「**搾取されないための基本戦略**」です。

ナッシュ均衡戦略上で取るべき行動は確率として計算することができます。これを理解した上で、その行動を出来ていない相手の弱点を突く（=**相手に対して期待値が高い戦略を取る**）ことで利益が出る、というのがナッシュ均衡を前提とした不完全情報ゲームのゲームプレイとなります。

ポーカーや麻雀のように不確定の情報のパターンが多いゲームにおいてのナッシュ均衡計算は膨大な時間がかかります。そのためナッシュ均衡戦略をAIに利用させるというのは大変難しい課題でした。

しかし囲碁や将棋で圧倒的な結果を出したAI技術を効果的に応用することで、2019年に6人対戦のテキサスホールデム向けのAIである**Pluribus**が誕生し、人間に圧勝しました。

この結果を踏まえて、麻雀にもゲーム理論を適用したのがLuckyJなのです。

##### ゲーム理論の導入が何故強さに繋がったのか

ここからは完全に私の私見になりますが、打牌と共にゲーム理論の影響が出ていそうなところを見てみましょう。  
お恥ずかしながら私の雀力は雀魂で雀豪に居る程度ですので、打牌の評価については後述するゆうせーさんのnoteなどを見て頂くのがオススメです。

![](https://r2.modern-jan.com/2023/09/tenhou.net_3__log2023053016gm-0029-0000-e54b3b98tw0-2-1024x808.avif)

トップ目のLucky J。ドラ色のホンイツ気配の下家に対してペン3m払い。

Lucky Jは1副露に対しては危ない牌から被せるようなプレイも多いです。  
・オリ過ぎは下家以外が楽になって得をする。  
・下家のホンイツの牌を早くから絞ると自分は圧倒的に損になる。  
・親の連荘は防ぎ、放銃はしたくない。下家に鳴かせて下3人でリスクを取り合ってもらう分には得。  
・ドラ表ペン3mは下家も持っていそうなので頼らず、赤5mにドラを引いて形が良くなれば手を組む価値アリ。

といった方針でしょうか？この後は対面の親からリーチが入り、下家ケアをしながら丁寧にオリていました。

![](https://r2.modern-jan.com/2023/09/tenhou.net_3__log2023053016gm-0029-0000-e54b3b98tw0-3-1024x808.avif)

こちら南3局では一気通貫の役あり聴牌を目指しつつ、ドラも使いたい意図を見せていたが、3段目に入り全体に対して対応を始めたLucky Jの図。  
下家の3s手出しに放銃して局を消化してもいいし、親の高い黙聴に打ちたくないのか？親の現物である1sの対子落としを初めています。

続いて打2pとした場面。

![](https://r2.modern-jan.com/2023/09/image-4-1024x940.avif)

もちろんNAGA的には打中推奨。

![](https://r2.modern-jan.com/2023/09/image-5-1024x663.avif)

孤立字牌の選択。これは和了を目指す牌効率的には当たり前ですね。3pの受けを失います。

しかしLuckyJはシャンテン数とタンヤオなどの役の出来にくさを加味して手狭に受け、安全牌を手に残しています。放銃を避けつつ、直線的な牌効率よりもシャンテン数と巡目、他家の速度に強い意識があるように思えます。

以上3場面を取り上げましたが、ゲームメイクの感覚、他者を意識したゲームプレイと言えるのではないでしょうか？このようなプレイスタイルをどこかで見たことがないでしょうか？

多井隆晴プロを始めとしたゲームメイクが上手いとされるプロの打牌です。

例えば多井隆晴プロは失点の少なさとゲームメイクが評価されています。悪い配牌に対しスリムな手組をしながら、価値のある手が出来たときだけ攻めに転じる「配牌オリ」はまさにLucky Jと重なるところがあります。

麻雀は平均で4回に1回しか和了チャンスがありません。その中で相手が和了を目指して来ることを想定しながら、価値のある手を作り、失点リスクを回避するというプレイはまさにナッシュ均衡的です。麻雀でいうならバランス感覚と表現されるものでしょうか？

### LuckyJまとめ

現代麻雀の歴史を振り返ると、手役重視の黎明期から「科学する麻雀」により愚形聴牌即リー上等の時代が到来し、現在は打点と速度のバランスを如何にして取るか、という段階に来ていると言えるでしょう。

しかし実際問題として4人でプレイする麻雀においての局単位・半荘単位の長期的な戦略というのは未だ研究が及んでいないジャンルです。あくまで自分の手牌が中心で、自分の攻撃手順をミスしないことと危険を察知した際に回避することが重視されています。

その中で数学的に最適と考えられている戦略を麻雀における局単位・半荘単位の戦略の切り替えの根拠として持ち込んだLucky Jが如何に画期的なのか。これは麻雀の戦術や理論を研究・勉強している人にとっては言うまでもないことでしょう。

私はLuckyJを神のみぞ知る最適境界線、荒削りな「神様のキューブ」に近づきつつある存在であると考えています。

### 注意

実は、ナッシュ均衡戦略が3人以上の零和ゲームにおいて最適なのかははっきりしていません。つまり、現状**たまたま人間や他のAIより強いだけ**かもしれません。

またナッシュ均衡が最適だとしても、ナッシュ均衡は2人までしか厳密な計算はできません。しかも計算が膨大すぎるのでポーカーの2人プレイについての計算ですら近似的な解を用いることが多いようです。よってLucky Jも現状「ナッシュ均衡戦略に近い戦略を得たAI」に過ぎないのです。（それでも破茶滅茶に凄いことなのですが）

4人麻雀においてAIが天鳳の待ち時間の中で打牌できるというのは本来凄いことなのです。今回は技術的な部分を避けているので触れていませんが、研究者たちが短時間で計算ができ、かつ成績が出るように情報を効果的に絞る研究をした結果がSuphxやLucky Jとも言えるのです。完璧ではありません。

つまり、SuphxやLuckyJは進化するかもしれませんし、これからもっと強いAIも出てくるでしょう。麻雀の最適戦略はこれだ！が見つかるかもしれません。とても楽しみですね。

## まとめ・麻雀AIから学ぶための学習コンテンツのススメ

まとめると

現NAGAは「**強者を模倣してバランスを高めたAI**」

Suphxは「**大量の経験によって大局観とメリハリ打法を身に着けたAI**」

LuckyJは「**ゲーム理論を麻雀に取り入れ、現状最も麻雀の神に近付こうとしているAI**」

です。我々は学習段階に応じて参考にしていくべきでしょう。

### 麻雀AIから学ぶには

麻雀AIはただでさえ難しい、という話を冒頭に出しましたが、それでもようやくここまで発展しました。囲碁や将棋においてAIが活用されているならば我々雀士も活用するべきでしょう。

しかし、セオリーを無視してSuphxやLucky Jの牌譜を漁るのが正解かと言えば大きな間違いです。これは既に現代のセオリーを学んで、人間の中で上位層の雀士が取るべき選択でしょう。

そうは言ってもセオリーに因われないAIが強いのに、セオリーを学ぶことが有効なのか疑問に思うかもしれません。

我々は人間だからです。AIのようなノーミスプレイが出来ないからです。瞬間で多門張の受け入れ枚数を正確に数え上げることもできないし、連続でラスを引けばメンタルを痛め、連続でトップを取れば調子に乗ってしまう存在だからです。我々の脳では現在の手牌から無数の選択肢をすべて想像し最適解を計算することは出来ません。ここで生きてくるのがパターン化、セオリーです。

例えば「この形は〇〇を切る」と言ったセオリーは登場シーンの多い形でミスを減らし、有利になるための有益なツールです。4枚形・7枚形の理解は認知負荷を減らし、他家の捨て牌や打点についての思考を回すために役立ちます。さらに言えば概ねセオリーというのは数学的にも正しいのです。

セオリーによって牌譜で着目すべき点を捉えられるようになってから、そのセオリーとAIの判断が乖離する部分を見つけ、その判断の根拠を牌譜から探すことがAI戦略の研究の第一歩であると思います。

つまり基礎をしっかりやってからAI戦術を取り入れるのが良さそうです。

### 麻雀AIから学ぶためのコンテンツ

初心者はルールと牌効率、ベタオリを学びましょう。平澤元気さんのYouTubeチャンネルや初心者向けの戦術本がおすすめです。

<LinkCard url="https://modern-jan.com/2022/04/13/haikouritsu/" />

中級者である雀魂雀豪や天鳳5段以上は少し高度な牌効率や押し引きを学ぶと良いと思います。ゆうせーさんのYoutubeチャンネルや書籍、渋川難波プロのチャンネルオススメです。

<LinkCard url="https://modern-jan.com/2023/09/05/middle_haikouritsu/" />

中級者に対しては打ち筋タイプごとのストレートな手組みを学ぶツールとして**NAGAの牌譜検討サービス**がおすすめです。現代の速度と打点のバランスを見た麻雀でミスを減らすという意味では大変有意義だと思います。

Lucky JやSuphxから学びたい！という方は多いでしょう。しかし牌理に苦労せず、押し引きもある程度習得した、という方でないとAIの牌譜を直接読むのは難しいでしょう。

そこでおすすめなのがお知らせさんのSuphx本とゆうせーさんのNAGA/Suphx/Lcuky Jについての麻雀戦術noteです。中級者以上の打ち手がセオリーとして取り入れられる部分や注目すべき思考をピックアップして紹介してくれています。

また、ゆうせーさんのLucky J検討配信は、セオリーとNAGA各モデルとLucky Jの比較をしながらの大変面白い配信です。戦略の取り入れ方の方針なども語ってくれる貴重な情報です。

#### ゆうせーさんのLuckyJコンテンツ（旧→新）

*   [天鳳位間近の最強AI【LuckyJ】をMリーグ観戦記者が丸裸にします。 - note](https://note.com/getawonarashite/n/n449ff8e33986?magazine_key=m5ac7ab04884e)
*   [ついに、人間は追い抜かれたのか。最強AI【LuckyJ】が見つめる先にあるものとは… - note](https://note.com/getawonarashite/n/nb93bc97ea0ac?magazine_key=m5ac7ab04884e)
*   [時代から取り残されないために… 最強AI【LuckyJ】から【超絶トイツテクニック】を盗め！ - note](https://note.com/getawonarashite/n/nd8c89f01d41e?magazine_key=m5ac7ab04884e)
*   [驚愕の打牌８連発！【最新AI】LuckyJ何切る問題集！vol.1 - note](https://note.com/getawonarashite/n/n8ba8d11e9eb6)
*   [【最強AI】LuckyJの牌譜をガチで検討します。vol.1 - YouTube](https://www.youtube.com/live/ylm1Is9r3lU?si=1RcMjNMHVtYhyHsi)
*   [【45000人＆3周年記念】LuckyJの牌譜をガチ検討します。【最強AI】vol.2 - YouTube](https://www.youtube.com/live/CYdi3La5Q0o?si=OTJEAIdjUwWGRoHx)
*   [【最強AI】LuckyJの牌譜をガチ検討します。vol.3 - YouTube](https://www.youtube.com/live/-_6_Qphh1tc?si=IdsqXiOxB36nW3sj)
*   [【最強AI】のラス牌譜から弱点を探します。LuckyJ牌譜検討vol.4！ - YouTube](https://www.youtube.com/live/lPcSnFggK3A?si=I1GfUTJrvRMhzjXg)

#### お知らせ本（以下アソシエイトリンク）

*   [世界最強麻雀AI Suphxの衝撃 (マイナビ麻雀BOOKS) - Amazon](https://amzn.to/3r0k3Fe)：お知らせさんのSuphx本、第１弾。
*   [世界最強麻雀AI Suphxの決断 (マイナビ麻雀BOOKS) - Amazon](https://amzn.to/44wd44s)：お知らせさんのSuphx本、第２弾。改良されたSuphxの牌譜を元にしている。

２冊ともKindle Unlimitedの対象です。他にも麻雀本はKindle Unlimitedの対象になっているものは多いです。[Kindle Unlimitedの登録はこちらから](https://www.amazon.co.jp/kindle-dbs/hz/signup?tag=kbkn08-22)

### 最後に

私は麻雀を楽しみたい人のためのツールの開発や私設リーグや大会の開催を行っています。

<LinkCard url="https://modern-jan.com/2022/07/19/mjrs/" />

もしこの記事を読んでためになったと思った方はぜひAmazonアソシエイトリンクを踏んだ上でお買い物して頂いたり（踏んでから一定時間内の決済が対象）、下のcodocから支援していただけると嬉しいです。

## 参考リンク

### 雀士向けのAI解説情報

*   [NAGA解析 VS Suphx ～麻雀に正解はあるのか～ - note](https://note.com/chiarittsu/n/n49f969b87ce5)：NAGAとSuphxの打牌選択の違いについて、Suphxの牌譜をNAGA解析にかけることで考察している。この記事はNAGA解析サービス初期のもので、おそらくv1.0-ω（10段到達時点のモデル）による解析と思われる。
*   [NAGA解析 VS Suphx Vol.2 ～ここがダメだよSuphx28選～ - note](https://note.com/chiarittsu/n/n8edcfee81572)

### LuckyJ情報

LuckyJ開発元のテンセントAI Labの公式記事：

<LinkCard url="https://mp.weixin.qq.com/s/yGH8rH05XvSFqWMl4VZWFw" />

*   [麻雀AI「Lucky J」についてのテンセント公式記事の日本語訳](https://modern-jan.com/2023/09/06/luckyj_article_ja/)：上記記事の日本語訳。拙訳ですがよければ。
*   [多人数不完全情報ゲームにおけるAI ~ポーカーと麻雀を例として~ | SlideShare](https://www.slideshare.net/slideshow/embed_code/key/6CRqIsNdKUwdLR)：ゲーム理論と不完全情報ゲームの関係性、なぜ3人以上のナッシュ均衡を求めるのが難しいのか、などについてはこちらの資料がわかりやすい。
*   [Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game](https://openreview.net/forum?id=DTXZqTNV5nW)：Lucky Jの開発陣が先んじて1対1麻雀でアルゴリズムの研究を行った論文。

### NAGA情報

*   [深層学習麻雀AI「NAGA」 - DWANGO MEDIA VILLAGE](https://dmv.nico/ja/articles/mahjong_ai_naga/)：NAGAの8段到達時点でリリースされたDWANGO公式の解説記事。
*   [麻雀AI「NAGA」](https://naga.dmv.nico/naga_report/top/)：NAGA解析サービスはこちら。
*   [麻雀AI NAGA(ナーガ) 特南十段 - Twitter](https://twitter.com/NAGA025)：NAGAの最新情報はこちらから。

### Suphx情報

*   [麻雀 AI Microsoft Suphx が人間のトッププレイヤーに匹敵する成績を達成 - Microsoft news](https://news.microsoft.com/ja-jp/2019/08/29/190829-mahjong-ai-microsoft-suphx/)：麻雀AIの歴史を概観しつつSuphxの実績を解説している。
*   [Microsoftの最強麻雀AI Suphx の論文ざっくり日本語訳（導入と概要まで） - Qiita](https://qiita.com/Intel0tw5727/items/e122197b5a2958a22b34)：エンジニア向けにSuphx論文を解説している。Suphxの中身について詳しく知りたい方におすすめ。
*   [Suphx論文を読んだ感想など - tomohxxの日記](https://tomohxx.hatenablog.com/entry/2020/04/25/230415)：恐らく現役エンジニアの方がまとめた論文の解説と感想がまとまっている。機械学習の知識がないと読むのは難しいが、論文を読むのはだるい、ぐらいの気持ちの人におすすめの記事。
*   [Suphx: Mastering Mahjong with Deep Reinforcement Learning - arxiv](https://arxiv.org/abs/2003.13590)：Suphxの論文。専門家の方はこちらをあたって欲しい。

### その他

*   [麻雀の扉](https://t.co/2GrXgwE4yg)：元のサイトは消滅していて、今は魚拓と呼ばれるアーカイブが残っている。園田賢プロや平澤元気さん、その他ネット麻雀有名人やプロなどファンが多いらしいサイト。神様のキューブという単語はここから拝借した。
